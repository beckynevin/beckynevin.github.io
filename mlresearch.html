
<html>
  <head>
    <meta charset="UTF-8">
    <title>Becky Nevin</title>
    <link rel="stylesheet" href="css/screen.css" type="text/css" media="screen, projection">
    <link rel="stylesheet" href="css/print.css" type="text/css" media="print">
    <link rel="stylesheet" type="text/css" href="css/becky.css">
    <!--[if IE]><link rel="stylesheet" href="css/blueprint/ie.css" type="text/css" media="screen, projection"><![endif]-->
<script type="text/javascript" language="JavaScript">

</script>


</head>

  <body>
    <div class="container">
      <div class="column span-24 first last">
	<h1>Becky Nevin</h1>
      </div>
      <hr>
    </div>
    <div class="container">

    <div class="span-4 first colborder">
        <a href="index.html">home</a><br>
        <a href="mlresearch.html">machine learning research</a><br>
        <a href="galresearch.html">galaxy research</a><br>
        <a href="news.html">news</a><br>
        <a href="outreach.html">science communication</a><br>
        <a href="writing.html">writing</a><br>
        <a href="talks.html">talks</a><br>
        <a href="stickers.html">stickers</a><br>
        <a href="misc.html">about me</a><br>
        <a href="cv.html">resume and cv</a><br>
      </div>
      <div class="span-16">

This page is under development.


<p><b>Testing the fidelity of uncertainty predictions from machine learning inference methods</b>
<p>With great machine learning power comes great responsibility.
<p>One of my roles in the Deepskies group is to develop and test tools for benchmarking and assessing uncertainty predictions from 
machine learning methods.
<img src="files/comparison_project.png" width=500 class="center">
<p>DeepUQ Github: <a href="https://github.com/deepskies/DeepUQ/tree/main">https://github.com/deepskies/DeepUQ/tree/main</a> 

<hr>
<p><b>DeepDiagnostics: Software for assessing the quality of inference</b>


<hr>
<p><b>Flexible benchmark datasets for machine learning research</b> 
<p>In order to evaluate the performance of ML tools for inference, I rely upon benchmark datasets.
In Deepskies lab, we have developed our own benchmark utilities (DeepBench), 
which produces simple astrophysical objects in a flexible framework that allows the user to control the noise properties.
Using simple tools like a pendulum with stochastic noise,
I am creating a methodology for comparing the bias and uncertainty in parameter estimation from various inference techniques. This type 
of simple dataset also allows me to experiment with comparing hierarchical to non-hierarchical inference paradigms (below).
<img src="files/one_pendulum.png" width=500 class="center">
<p>DeepBench Github: <a href="https://github.com/deepskies/DeepBench">https://github.com/deepskies/DeepBench</a>

<hr>
<p><b>Hierarchical Bayesian inference and simulation based inference (SBI)</b>
<p>Hierarchical inference is an important tool for estimating parameters of individual data units as well as global parameters.
This is especially relevant to estimating cosmological parameters, for instance in the case of multiple strong lenses in an all sky imaging survey; the goal is to estimate the individual lens parameters as well as global cosmological parameters.
<p>Using the above uncertainty framework, I compare various state-of-the-art inference techniques such as <b>hierarchical inference (sampling)</b> and <b>simulation based inference</b>.
<img src="files/hierarchical_pendulum.png" width=500 class="center">
^Using the benchmark pendulum dataset to compare the performance of hierarchical sampling and SBI.

<hr>
<p><b>Harnessing machine learning to improve Chandra HRC</b>                                                                                                                                           
<p>I have worked closely with Chandra leadership to develop a machine learning framework, <a href="https://github.com/beckynevin/EVE">EVE</a>, to distinguish between real X-ray events and background events (such as cosmic rays). An improved background identification technique is highly valued by the X-ray community, as it would greatly improve the S/N of future and archival Chandra observations. However, this is a huge challenge, as X-ray events are highly multi-dimensional (i.e., each event has information about the time of arrival, position, and energy) and we lack labelled synthetic data. 
<img src="files/Chandra_ML.png" width=500 class="center">
<p> With EVE, I am pursuing a multi-pronged approach for background classification, using multiple options for machine learning algorithms such as a supervised random forest and a semi-supervised bagging classifier that learns from X-ray observations on the fly. The figure above shows an example of the semi-supervised technique assigning probability values to events.


    <hr>

      
      </div>




        </script>

      </div>



    </div>
  </body>
</html>
